{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23cf47df",
   "metadata": {},
   "source": [
    "### Imports and loading "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4980bebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import dspy\n",
    "from prompt_optimization.seed_prompts import ATOMIZER_PROMPT, PLANNER_PROMPT, AGGREGATOR_PROMPT, ATOMIZER_DEMOS, PLANNER_DEMOS\n",
    "from dspy import GEPA\n",
    "\n",
    "from prompt_optimization import (\n",
    "    get_default_config,\n",
    "    LMConfig,\n",
    "    patch_romaconfig,\n",
    "    load_aimo_datasets,\n",
    "    ComponentJudge,\n",
    "    MetricWithFeedback,\n",
    "    create_optimizer,\n",
    ")\n",
    "from prompt_optimization.seed_prompts import (\n",
    "    ATOMIZER_PROMPT,\n",
    "    ATOMIZER_DEMOS,\n",
    "    PLANNER_PROMPT,\n",
    "    PLANNER_DEMOS,\n",
    "    AGGREGATOR_PROMPT,\n",
    ")\n",
    "from roma_dspy.config import load_config\n",
    "from roma_dspy.core.engine.solve import RecursiveSolver\n",
    "from roma_dspy.core.modules.recursive_solver import RecursiveSolverModule\n",
    "from roma_dspy.utils import AsyncParallelExecutor\n",
    "\n",
    "dspy.settings.provide_traceback = True  # optional but mirrors the old notebook\n",
    "opt_cfg = load_config(profile=\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa039eb3",
   "metadata": {},
   "source": [
    "### Config LLMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1335161d",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_cfg.atomizer_lm = LMConfig(\"cerebras/qwen-3-235b-a22b-instruct-2507\", temperature=0.35, max_tokens=128_000)\n",
    "opt_cfg.planner_lm = LMConfig(\"cerebras/qwen-3-235b-a22b-instruct-2507\", temperature=0.3, max_tokens=128_000)\n",
    "opt_cfg.executor_lm = LMConfig(\"cerebras/gpt-oss-120b\", temperature=0.6, max_tokens=128_000)\n",
    "opt_cfg.aggregator_lm = LMConfig(\"cerebras/gpt-oss-120b\", temperature=0.4, max_tokens=64_000)\n",
    "opt_cfg.judge_lm = LMConfig(\"openrouter/anthropic/claude-sonnet-4.5\", temperature=0.75, max_tokens=128_000, cache=True)\n",
    "opt_cfg.reflection_lm = LMConfig(\"openrouter/anthropic/claude-sonnet-4.5\", temperature=0.9, max_tokens=64_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f020b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch the knobs you used to tweak in the notebook.\n",
    "opt_cfg.train_size = 32\n",
    "opt_cfg.val_size = 8\n",
    "opt_cfg.test_size = 8\n",
    "opt_cfg.dataset_seed = 42\n",
    "opt_cfg.max_metric_calls = 225\n",
    "opt_cfg.num_threads = 8\n",
    "opt_cfg.max_parallel = 4\n",
    "opt_cfg.concurrency = 4\n",
    "opt_cfg.max_depth = 1\n",
    "opt_cfg.enable_logging = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09db50ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add few-shot examples + prompts\n",
    "opt_cfg.agents.atomizer.signature_instructions = ATOMIZER_PROMPT\n",
    "opt_cfg.agents.planner.signature_instructions = PLANNER_PROMPT\n",
    "opt_cfg.agents.aggregator.signature_instructions = AGGREGATOR_PROMPT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6af57c",
   "metadata": {},
   "source": [
    "### Init solvers and what not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700e9d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "solver = RecursiveSolver(\n",
    "    config=opt_cfg,\n",
    "    max_depth=opt_cfg.max_depth,\n",
    "    enable_logging=opt_cfg.enable_logging,\n",
    "    enable_checkpoints=False,\n",
    ")\n",
    "solver_module = RecursiveSolverModule(solver=solver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bf6afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "judge = ComponentJudge(lm_config=opt_cfg.judge_lm)  # keyword required after the refactor\n",
    "metric = MetricWithFeedback(judge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b667a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, val_set, test_set = load_aimo_datasets(\n",
    "    train_size=opt_cfg.train_size,\n",
    "    val_size=opt_cfg.val_size,\n",
    "    test_size=opt_cfg.test_size,\n",
    "    seed=opt_cfg.dataset_seed,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25b0d72",
   "metadata": {},
   "source": [
    "### Perform an eval on the val set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcacaefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# executor = AsyncParallelExecutor(max_concurrency=4)\n",
    "\n",
    "# results = await executor.execute_batch(solver_module, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d486a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc320b30",
   "metadata": {},
   "source": [
    "### Prompt tuning stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34080e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = GEPA(\n",
    "    metric=metric,\n",
    "    # auto=\"light\",\n",
    "    component_selector=\"round_robin\",\n",
    "    max_metric_calls=12,\n",
    "    add_format_failure_as_feedback=True,\n",
    "    num_threads=12,\n",
    "    track_stats=True,\n",
    "    log_dir=\"logs/aime_test\",\n",
    "    # use_wandb=True,\n",
    "    # wandb_init_kwargs={\"project\": \"aime_test\"},\n",
    "    reflection_minibatch_size=8,\n",
    "    reflection_lm=dspy.LM(model=\"openrouter/anthropic/claude-sonnet-4.5\", temperature=.75, max_tokens=128000)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85bcee5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_program = optimizer.compile(\n",
    "    solver_module,\n",
    "    trainset=train_set,\n",
    "    valset=val_set,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3642c2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6416bde3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
