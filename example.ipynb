{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75427881",
   "metadata": {},
   "outputs": [],
   "source": [
    "from roma_dspy import RecursiveSolver, Executor, Atomizer, Planner, Aggregator\n",
    "import dspy \n",
    "\n",
    "executor_lm = dspy.LM(\"openrouter/google/gemini-2.5-flash\", cache=False)\n",
    "atomizer_lm = dspy.LM(\"openrouter/google/gemini-2.5-flash\", cache=False)\n",
    "planner_lm = dspy.LM(\"openrouter/google/gemini-2.5-flash\", cache=False)\n",
    "aggregator_lm = dspy.LM(\"openrouter/google/gemini-2.5-flash\", cache=False)\n",
    "\n",
    "# Initialize modules\n",
    "atomizer = Atomizer(lm=atomizer_lm)\n",
    "planner = Planner(lm=planner_lm)\n",
    "executor = Executor(lm=executor_lm)\n",
    "aggregator = Aggregator(lm=aggregator_lm)\n",
    "\n",
    "# Create solver\n",
    "solver = RecursiveSolver(\n",
    "    atomizer,\n",
    "    planner,\n",
    "    executor,\n",
    "    aggregator,\n",
    "    max_depth=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b9a8e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_goal = \"Write me a blog post about the benefits of using DSPy.\"\n",
    "\n",
    "root = await solver.async_event_solve(task_goal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c254671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Unlocking LLM Potential: Why DSPy is a Game-Changer for AI Development\n",
      "\n",
      "## I. Introduction\n",
      "\n",
      "Are you tired of wrestling with complex prompt engineering, struggling to get consistent and reliable outputs from your Large Language Models (LLMs)? What if there was a way to program LLMs more systematically, like traditional software, and achieve significantly better results with less effort?\n",
      "\n",
      "Enter DSPy, a groundbreaking framework designed to optimize and program LLMs. Unlike traditional prompt engineering, which often relies on trial-and-error, DSPy treats LLMs as components within a larger program, allowing developers to compose, compile, and optimize complex LLM pipelines. It provides a systematic approach to building robust and efficient LLM-powered applications, moving beyond simple prompting to a more structured and performant paradigm.\n",
      "\n",
      "In an era where LLMs are becoming central to countless applications, the ability to reliably and efficiently develop with them is paramount. DSPy addresses this critical need by offering a principled way to improve LLM performance, reduce development time, and build more scalable and maintainable AI systems. It empowers developers to unlock the full potential of LLMs, transforming them from unpredictable black boxes into programmable, optimizable agents.\n",
      "\n",
      "## II. The Core Benefits of DSPy\n",
      "\n",
      "### 1. Programmatic Control and Structured Development\n",
      "\n",
      "DSPy fundamentally shifts the paradigm from \"prompt engineering\" to \"program engineering.\" It allows you to treat LLMs not as black boxes to be coaxed with magic words, but as functions within a larger, structured program. This means:\n",
      "\n",
      "*   **Traditional Software Engineering Practices:** You can apply familiar software development principles like modularity, abstraction, and version control to your LLM applications.\n",
      "*   **Explicit Modules and Signatures:** DSPy replaces ad-hoc, unstructured prompts with explicit `dspy.Signature` definitions and modular components (like `dspy.Predict` or `dspy.ChainOfThought`). This clearly defines the inputs and outputs of each LLM call, making your LLM interactions readable, maintainable, and testable.\n",
      "*   **Clear Logic:** It allows for a clear definition of inputs, outputs, and intermediate steps within LLM applications, making complex reasoning pipelines easier to understand and debug.\n",
      "\n",
      "### 2. Automatic Optimization and Performance Gains\n",
      "\n",
      "This is where DSPy truly shines. Instead of manually tweaking prompts, DSPy introduces \"optimizers\" (also called Teleprompters or Compilers) that automatically learn how to improve your LLM programs.\n",
      "\n",
      "*   **Automated Prompt and Weight Optimization:** DSPy \"compiles\" LLM programs to automatically optimize prompts, few-shot examples, and even model weights for specific tasks and datasets.\n",
      "*   **Reduced Manual Effort:** It significantly reduces the need for manual, trial-and-error prompt engineering, saving countless hours of development time.\n",
      "*   **Improved Accuracy and Robustness:** By systematically optimizing the program, DSPy improves task accuracy, robustness, and generalization across different LLMs and datasets. It learns to generate better prompts, demonstrations, and reasoning steps automatically, leading to more consistent and reliable outputs.\n",
      "\n",
      "### 3. Modularity and Composable Pipelines\n",
      "\n",
      "DSPy encourages a modular approach to building LLM applications, much like building with LEGO bricks.\n",
      "\n",
      "*   **Break Down Complexity:** It enables breaking down complex LLM tasks into smaller, manageable, and reusable modules. For example, one module might extract entities, another might summarize, and a third might generate a response.\n",
      "*   **Sophisticated Reasoning:** You can easily chain and combine these modules to build sophisticated, multi-step reasoning pipelines, such as a `dspy.ReAct` agent that plans, acts, and observes.\n",
      "*   **Reusability:** This promotes the reusability of LLM components across different applications and projects, simplifying development, debugging, and maintenance.\n",
      "\n",
      "### 4. Systematic Evaluation and Debugging\n",
      "\n",
      "Moving beyond subjective assessments, DSPy provides a robust framework for objective evaluation.\n",
      "\n",
      "*   **Data-Driven Improvement:** It provides a robust framework for defining metrics and systematically evaluating LLM program performance against a dataset.\n",
      "*   **Identify Bottlenecks:** This facilitates data-driven testing and comparison of different LLM approaches and configurations, helping you identify bottlenecks, errors, and areas for improvement within your LLM pipelines.\n",
      "*   **Objective Optimization:** DSPy moves beyond subjective assessment to enable objective, quantifiable optimization of LLM applications, ensuring your improvements are real and measurable.\n",
      "\n",
      "### 5. Cost-Effectiveness and Efficiency\n",
      "\n",
      "Beyond performance, DSPy also offers tangible economic benefits.\n",
      "\n",
      "*   **Reduced API Costs:** Optimized prompts often lead to fewer tokens used per inference, directly reducing API costs, especially for high-volume applications.\n",
      "*   **Less Rework:** Improved accuracy and reliability reduce the need for re-runs, human correction, or fallback mechanisms, saving time and resources.\n",
      "*   **Leverage Smaller Models:** DSPy can enable the effective use of smaller, more cost-efficient LLMs for certain tasks by optimizing their performance to match or even exceed larger models.\n",
      "*   **Accelerated Development:** Most importantly, it significantly reduces development time and effort compared to manual, iterative prompt engineering, allowing teams to build and deploy faster.\n",
      "\n",
      "## III. Conclusion\n",
      "\n",
      "In summary, embracing DSPy offers a transformative path to building robust and efficient LLM applications. It empowers developers to achieve unparalleled performance, make data-driven decisions, and foster a culture of continuous innovation in AI development. By leveraging its capabilities, organizations can not only overcome current challenges in prompt engineering but also secure a significant competitive advantage in an ever-evolving AI landscape.\n",
      "\n",
      "The future of LLM development is here, and it's powered by DSPy. Don't just adapt to the complexities of LLMs; master them. Start your journey towards a more efficient, insightful, and innovative LLM-powered future today.\n"
     ]
    }
   ],
   "source": [
    "print(root.result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb15237f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m================================================================================\u001b[0m\n",
      "\u001b[1müìä HIERARCHICAL TASK DECOMPOSITION TREE\u001b[0m\n",
      "\u001b[36m================================================================================\u001b[0m\n",
      "\n",
      "‚îî‚îÄ‚îÄ ‚úÖ \u001b[33m[D0/2]\u001b[0m \u001b[94mWrite me a blog post about the benefits of using DSPy.\u001b[0m \u001b[35müìùPLAN\u001b[0m [\u001b[92mCOMPLETED\u001b[0m]\n",
      "    ‚è±Ô∏è  \u001b[32m8.90s\u001b[0m\n",
      "    üîç atomizer: 1.22s\n",
      "    üîÑ aggregator: 7.67s\n",
      "    ‚îú‚îÄ‚îÄ ‚úÖ \u001b[33m[D1/2]\u001b[0m \u001b[94mResearch DSPy to understand its core concepts, functional...\u001b[0m \u001b[35müìùPLAN\u001b[0m [\u001b[92mCOMPLETED\u001b[0m]\n",
      "    ‚îÇ   ‚è±Ô∏è  \u001b[32m5.76s\u001b[0m\n",
      "    ‚îÇ   üîç atomizer: 1.11s\n",
      "    ‚îÇ   üîÑ aggregator: 4.66s\n",
      "    ‚îÇ   ‚îú‚îÄ‚îÄ ‚úÖ \u001b[33m[D2/2]\u001b[0m \u001b[94mFind the official DSPy documentation and any high-level o...\u001b[0m \u001b[35m‚ö°EXECUTE\u001b[0m [\u001b[92mCOMPLETED\u001b[0m]\n",
      "    ‚îÇ   ‚îÇ   ‚è±Ô∏è  \u001b[32m2.35s\u001b[0m\n",
      "    ‚îÇ   ‚îÇ   ‚ö° executor: 2.35s\n",
      "    ‚îÇ   ‚îú‚îÄ‚îÄ ‚úÖ \u001b[33m[D2/2]\u001b[0m \u001b[94mRead through the official DSPy documentation (e.g., 'Intr...\u001b[0m \u001b[35m‚ö°EXECUTE\u001b[0m [\u001b[92mCOMPLETED\u001b[0m]\n",
      "    ‚îÇ   ‚îÇ   ‚è±Ô∏è  \u001b[32m3.36s\u001b[0m\n",
      "    ‚îÇ   ‚îÇ   ‚ö° executor: 3.36s\n",
      "    ‚îÇ   ‚îú‚îÄ‚îÄ ‚úÖ \u001b[33m[D2/2]\u001b[0m \u001b[94mIdentify and list the main functionalities offered by DSP...\u001b[0m \u001b[35m‚ö°EXECUTE\u001b[0m [\u001b[92mCOMPLETED\u001b[0m]\n",
      "    ‚îÇ   ‚îÇ   ‚è±Ô∏è  \u001b[32m3.96s\u001b[0m\n",
      "    ‚îÇ   ‚îÇ   ‚ö° executor: 3.96s\n",
      "    ‚îÇ   ‚îú‚îÄ‚îÄ ‚úÖ \u001b[33m[D2/2]\u001b[0m \u001b[94mDetermine and articulate the primary benefits of using DS...\u001b[0m \u001b[35m‚ö°EXECUTE\u001b[0m [\u001b[92mCOMPLETED\u001b[0m]\n",
      "    ‚îÇ   ‚îÇ   ‚è±Ô∏è  \u001b[32m5.26s\u001b[0m\n",
      "    ‚îÇ   ‚îÇ   ‚ö° executor: 5.26s\n",
      "    ‚îÇ   ‚îî‚îÄ‚îÄ ‚úÖ \u001b[33m[D2/2]\u001b[0m \u001b[94mSynthesize all gathered information on DSPy's core concep...\u001b[0m \u001b[35m‚ö°EXECUTE\u001b[0m [\u001b[92mCOMPLETED\u001b[0m]\n",
      "    ‚îÇ       ‚è±Ô∏è  \u001b[32m5.59s\u001b[0m\n",
      "    ‚îÇ       ‚ö° executor: 5.59s\n",
      "    ‚îú‚îÄ‚îÄ ‚úÖ \u001b[33m[D1/2]\u001b[0m \u001b[94mCreate a detailed outline for the blog post, including an...\u001b[0m \u001b[35müìùPLAN\u001b[0m [\u001b[92mCOMPLETED\u001b[0m]\n",
      "    ‚îÇ   ‚è±Ô∏è  \u001b[32m9.09s\u001b[0m\n",
      "    ‚îÇ   üîç atomizer: 1.08s\n",
      "    ‚îÇ   üîÑ aggregator: 8.02s\n",
      "    ‚îÇ   ‚îú‚îÄ‚îÄ ‚úÖ \u001b[33m[D2/2]\u001b[0m \u001b[94mIdentify the core benefits and key features of DSPy that ...\u001b[0m \u001b[35m‚ö°EXECUTE\u001b[0m [\u001b[92mCOMPLETED\u001b[0m]\n",
      "    ‚îÇ   ‚îÇ   ‚è±Ô∏è  \u001b[32m5.44s\u001b[0m\n",
      "    ‚îÇ   ‚îÇ   ‚ö° executor: 5.44s\n",
      "    ‚îÇ   ‚îú‚îÄ‚îÄ ‚úÖ \u001b[33m[D2/2]\u001b[0m \u001b[94mDraft an introduction for the blog post outline, includin...\u001b[0m \u001b[35m‚ö°EXECUTE\u001b[0m [\u001b[92mCOMPLETED\u001b[0m]\n",
      "    ‚îÇ   ‚îÇ   ‚è±Ô∏è  \u001b[32m4.83s\u001b[0m\n",
      "    ‚îÇ   ‚îÇ   ‚ö° executor: 4.83s\n",
      "    ‚îÇ   ‚îú‚îÄ‚îÄ ‚úÖ \u001b[33m[D2/2]\u001b[0m \u001b[94mFor each identified benefit of DSPy, create a dedicated s...\u001b[0m \u001b[35m‚ö°EXECUTE\u001b[0m [\u001b[92mCOMPLETED\u001b[0m]\n",
      "    ‚îÇ   ‚îÇ   ‚è±Ô∏è  \u001b[32m5.74s\u001b[0m\n",
      "    ‚îÇ   ‚îÇ   ‚ö° executor: 5.74s\n",
      "    ‚îÇ   ‚îú‚îÄ‚îÄ ‚úÖ \u001b[33m[D2/2]\u001b[0m \u001b[94mDraft a conclusion for the blog post outline, summarizing...\u001b[0m \u001b[35m‚ö°EXECUTE\u001b[0m [\u001b[92mCOMPLETED\u001b[0m]\n",
      "    ‚îÇ   ‚îÇ   ‚è±Ô∏è  \u001b[32m2.01s\u001b[0m\n",
      "    ‚îÇ   ‚îÇ   ‚ö° executor: 2.01s\n",
      "    ‚îÇ   ‚îî‚îÄ‚îÄ ‚úÖ \u001b[33m[D2/2]\u001b[0m \u001b[94mReview and refine the entire blog post outline for clarit...\u001b[0m \u001b[35m‚ö°EXECUTE\u001b[0m [\u001b[92mCOMPLETED\u001b[0m]\n",
      "    ‚îÇ       ‚è±Ô∏è  \u001b[32m1.03s\u001b[0m\n",
      "    ‚îÇ       ‚ö° executor: 1.03s\n",
      "    ‚îî‚îÄ‚îÄ ‚úÖ \u001b[33m[D1/2]\u001b[0m \u001b[94mWrite the full blog post content based on the approved ou...\u001b[0m \u001b[35müìùPLAN\u001b[0m [\u001b[92mCOMPLETED\u001b[0m]\n",
      "        ‚è±Ô∏è  \u001b[32m5.27s\u001b[0m\n",
      "        üîç atomizer: 997.8ms\n",
      "        üîÑ aggregator: 4.28s\n",
      "        ‚îî‚îÄ‚îÄ ‚úÖ \u001b[33m[D2/2]\u001b[0m \u001b[94mWrite the full blog post content based on the approved ou...\u001b[0m \u001b[35m‚ö°EXECUTE\u001b[0m [\u001b[92mCOMPLETED\u001b[0m]\n",
      "            ‚è±Ô∏è  \u001b[32m13.73s\u001b[0m\n",
      "            ‚ö° executor: 13.73s\n",
      "\n",
      "\u001b[36m================================================================================\u001b[0m\n",
      "\u001b[1müìà EXECUTION STATISTICS\u001b[0m\n",
      "\n",
      "Task Status Distribution:\n",
      "  ‚úÖ COMPLETED: 15\n",
      "\n",
      "Depth Distribution:\n",
      "  Level 0: ‚ñà (1 tasks)\n",
      "  Level 1: ‚ñà‚ñà‚ñà (3 tasks)\n",
      "  Level 2: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà (11 tasks)\n",
      "\n",
      "Total Tasks: 15\n",
      "Subgraphs Created: 1\n",
      "Execution Complete: ‚úÖ Yes\n"
     ]
    }
   ],
   "source": [
    "from roma_dspy.visualizer import TreeVisualizer, StatisticsVisualizer, HierarchicalVisualizer# Get the DAG for detailed visualization\n",
    "\n",
    "# Show the full execution report\n",
    "tree = TreeVisualizer(use_colors=True, show_timing=True)\n",
    "print(tree.visualize(root, dag=solver.last_dag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba29d62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
